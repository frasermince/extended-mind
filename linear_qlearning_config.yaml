agent_name: "linear_qlearning"
parquet_folder: "./parquet"
capture_video: false

seed: 1
agent_view_size: 3
max_steps: 1000
path_mode: "VISITED_CELLS"
show_landmarks: false

render_options:
  show_grid_lines: false
  show_walls_pov: false
  show_optimal_path: true

training:
  env_id: "MiniGrid-SaltAndPepper-v0-custom"
  total_timesteps: 200000
  discount: 0.95
  step_size: .002
  start_epsilon: 0.05
  end_epsilon: 0.05
  exploration_fraction: 1
  agent_pixel_view_edge_dim: 24
  q_network_type: "flax"
  
eval_params:
  action_mode: "RECORDED_ACTIONS"
  hardcoded_actions: null # todo for now comment out
  parquet_path: null # this is the path to the parquet file that contains the agent params and action recordings we might want to use in eval


eval: false
train: true

# Basic nonstationary params
nonstationary_path_decay_pixels: 650
nonstationary_path_decay_chance: .25
nonstationary_path_inclusion_pixels: 24

# Counter based
nonstationary_visitations_before_path_appearance: 1
nonstationary_max_path_count: 1

# Seasonal
nonstationary_steps_before_path_visible: 0

# Only optimal param
nonstationary_only_optimal: false

tile_size: 8

path_width: 3