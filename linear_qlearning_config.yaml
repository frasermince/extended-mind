agent_name: "linear_qlearning"
parquet_folder: "./parquet"

seed: 1
agent_view_size: 3
max_steps: 1000
path_mode: "VISITED_CELLS"

render_options:
  show_grid_lines: false
  show_walls_pov: false
  show_optimal_path: true

training:
  env_id: "MiniGrid-SaltAndPepper-v0-custom"
  total_timesteps: 200000
  discount: 0.95
  step_size: 1e-3
  start_epsilon: 1.0
  end_epsilon: 0.01
  exploration_fraction: 0.5
  agent_pixel_view_edge_dim: 20
  q_network_type: "flax"

capture_video: false

eval: false
train: true

eval_params:
  action_mode: "RECORDED_ACTIONS"
  hardcoded_actions: null # todo for now comment out
  parquet_path: null # this is the path to the parquet file that contains the agent params and action recordings we might want to use in eval
  

nonstationary_path_decay_pixels: 720
nonstationary_path_decay_chance: .25
nonstationary_path_inclusion_pixels: 16
show_landmarks: false
